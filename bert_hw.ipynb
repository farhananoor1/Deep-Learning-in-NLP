{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HvOQu_LzDfQ"
      },
      "source": [
        "Your task is to create a bert-base-classifier of vacancy areas based on their titles.\n",
        "\n",
        "Each vacancy can have more than one area so it's **Multi-label classification** not Multiclass classification\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c3hdjB2RyKL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQeDJowaSZEz",
        "outputId": "5abd284d-34c1-47e0-b66d-eb72e55f1fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1aZ70ahRyKN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, RandomSampler, Dataset, SequentialSampler\n",
        "import random\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JS2FDgx0bJ8"
      },
      "source": [
        "# Try two or more different bert-like models(different berts, robertas etc. or any other transformer based model) (**2 points max**)\n",
        " your notebook should contain the training process of all your models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXRlAwjRpNH4"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'bert-base-uncased'\n",
        "MAX_SEQ_LENGTH = 128  # Adjust based on text length\n",
        "RESULT_MODEL_PATH = './model.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqROX-m_RyKO"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed = 12\n",
        "seed_everything(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jt3I5yjRyKO"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtFup4zDRyKO",
        "outputId": "b0f94bd8-ddc8-4ae0-cec6-d411944e6c90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBqvVxHcRyKP"
      },
      "outputs": [],
      "source": [
        "punctuation = set('!\"$%&\\'()*,-/:;<=>?@[\\\\]^_`{|}~')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfJcF7aTRyKP"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    return ' '.join([token.lower() for token in word_tokenize(text) if token not in punctuation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ooirSdcRyKQ",
        "outputId": "7da5c93e-eb56-4033-bdb7-d1a9288e0e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          title            area\n",
            "0      Expert Java Developer (Technical Leader)      programmer\n",
            "1               Software Engineer (JVM Runtime)      programmer\n",
            "2                                 PHP developer      programmer\n",
            "3                             Backend developer      programmer\n",
            "4                             Backend developer      programmer\n",
            "...                                         ...             ...\n",
            "78904    Business Analyst (Embedded Department)         analyst\n",
            "78905         Data Scientist (speech synthesis)  data_scientist\n",
            "78906  Middle / Senior BackEnd Developer (Java)      programmer\n",
            "78907                   Marketing Product Owner           owner\n",
            "78908                     Middle ABAP Developer      programmer\n",
            "\n",
            "[78909 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('dataset_2020.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjHJjyuIpuoP",
        "outputId": "d2f75af0-f8e1-4f56-bb29-859d9f546b62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78909, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isHu3xEPqN3T"
      },
      "outputs": [],
      "source": [
        "df['title'] = df['title'].apply(clean)  # Clean text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKZKNpkH1a96"
      },
      "source": [
        "Each vacancy can have more than one area separated be space\n",
        "\n",
        "Exapmle:\n",
        "\n",
        "Malware Analyst for Imunify Security,analyst it_security"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMLwKmUjRyKQ"
      },
      "outputs": [],
      "source": [
        "df_train, df_test = train_test_split(df, train_size=0.9, random_state=42)\n",
        "df_train, df_valid = train_test_split(df_train, train_size=0.8, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycsv3up02l1M"
      },
      "source": [
        "# Finish TextClassificationDataset (**1 point max**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZHXZHMiqjlz"
      },
      "outputs": [],
      "source": [
        "# Dataset Class\n",
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, binarizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.sentences = [clean(sent) for sent in data['title'].tolist()]\n",
        "        self.targets = [labels.split() for labels in data['area'].tolist()]\n",
        "        self.binarizer = binarizer\n",
        "        self.target_one_hot = torch.tensor(self.binarizer.transform(self.targets), dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            self.sentences[idx],\n",
        "            max_length=MAX_SEQ_LENGTH,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoded['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoded['attention_mask'].squeeze(0),\n",
        "            'target': self.target_one_hot[idx]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "695e68a5a11b4b6eabad1cab165cdb00",
            "37457dd94fc440ab9bd139707c66e2db",
            "bb32e3ee157140e48bd46556a91e77ca",
            "2498bb0f995749fcb2a48a9ed22ec739",
            "1b0084929fc34a6393c46344fdc66b66",
            "daf17f2ac44246afa023ccf2040a5b65",
            "24da5344c972484b90f4ec72f6ce21cf",
            "19d033a8c81e4b4681f659bb1717e6f7",
            "59bfa596451d44f79eb144f26b2ba20e",
            "a245d9ba49db46f3951cc920c2ec542d",
            "c3e1ebecb3644a5d8a0049c4369a19f4",
            "de5faebaadce4a78b3698a36cc33d325",
            "2442d1348f704b3a8d0f66a88db93c55",
            "2496556f9f934a31b49715eb88fe0b13",
            "8f832f9cc5004922ad6d64ffdce79b94",
            "97c11e58b22d46a6a812e8c7fda12981",
            "4ad527825ebb49ccaadf6edad4d5a52a",
            "f5b76b58cb6c43219de4f766b6365e7d",
            "f3e65c79c92c4634ba4454e2f0f407c7",
            "44275fbe98a642bb8e42476819d49e88",
            "f9f309d1d0ce4a6a862b75695dcf8821",
            "75cd573a19be40d7bdebcb79d6d1d480",
            "8988e659bbb14821afb376d2f263a36b",
            "7a25693f8a3a423c894b883f35159a83",
            "6cdd2d7f0c2a4b9da2d8128117a94130",
            "57861e88f6dd4d1db74b9255b7c6275f",
            "944af54a02284da7b212097869f26599",
            "060b087e5c1349adbdf7186dd92f7b33",
            "001adfff5c0841e1b264262145bdcc7d",
            "4614faf814534be18199bd5d5983ccd1",
            "6db33884875e43cfb75c49662aaf9525",
            "059c7579c8514cb9a9345999d0d81e7e",
            "ebc5885c29e5497e8ad8c3cbc2703bf3",
            "ac05961f78f245ba96358d549127e177",
            "ae4388d7fc3e4a738fe0d8167dd3dbad",
            "3207fd57756349edb2e5c45526ee3728",
            "da0f4aba8376479cb9e71bf86c0d9163",
            "24cb7009ef7f46acbbeeb351b6ff3a94",
            "6b9f4d85e2ab44658bf6c7596498c372",
            "2b1229cc246c48d1834423f9ec38e201",
            "a287e67f801b497196b735a52fcb26bc",
            "7fa0584b2c624bffa244b3cad69d441d",
            "09c425b792cc4866909a9a779ca54504",
            "1c1887a50c09431e8df23bb4b59506eb"
          ]
        },
        "id": "rGj0pO89RyKS",
        "outputId": "56a32d19-b35a-4bd7-f0ec-ee2141dbbbc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "695e68a5a11b4b6eabad1cab165cdb00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de5faebaadce4a78b3698a36cc33d325"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8988e659bbb14821afb376d2f263a36b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac05961f78f245ba96358d549127e177"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiLabelBinarizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultiLabelBinarizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\">?<span>Documentation for MultiLabelBinarizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultiLabelBinarizer()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "binarizer = MultiLabelBinarizer()\n",
        "labels_train = [labels.split() for labels in df_train.area.tolist()]\n",
        "binarizer.fit(labels_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5fYIqRsRyKS"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_dataset = TextClassificationDataset(df_train, tokenizer, binarizer)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_dataloader =  DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size,)\n",
        "\n",
        "valid_dataset = TextClassificationDataset(df_valid, tokenizer, binarizer)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "\n",
        "test_dataset = TextClassificationDataset(df_test, tokenizer, binarizer)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CC17o07q0Dt"
      },
      "outputs": [],
      "source": [
        "# Model Class\n",
        "class BertForMultilabel(nn.Module):\n",
        "    def __init__(self, num_labels: int):\n",
        "        super().__init__()\n",
        "        self.bert = transformers.BertModel.from_pretrained(MODEL_NAME)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def train_bert(self, train_bert_flag=True):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = train_bert_flag\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = self.classifier(outputs.pooler_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835,
          "referenced_widgets": [
            "b7447a4c04fd4054b17f4c927e70bfb2",
            "1fa462840ef14c4ab7710dabb1907b9f",
            "fd674f0106b2449c8292dba06fac0876",
            "817752425c484e52963756f3cd11329a",
            "783d91e89af24505975ab04ff3bbda8d",
            "33378a6c6446477886132a3bc6ff2ed8",
            "ddfd7c4325274f0ca98cb20146c4abdf",
            "5211de939ef44c978f52335ecbab6282",
            "9f52d6845abb4705bc1f3d1a6efafaa5",
            "975859023db04e25bee461b2428a2224",
            "3fb67420180e419aaf5e76e301b8a4c9"
          ]
        },
        "id": "4jalXjIRRyKT",
        "outputId": "bb0425d5-ded1-4b64-f161-df8fa8bed2a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7447a4c04fd4054b17f4c927e70bfb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMultilabel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=29, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "num_labels = len(binarizer.classes_)\n",
        "model = BertForMultilabel(num_labels)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dYnx8KC28_V"
      },
      "source": [
        "# Train your classifier with freezed bert and save model with the lowest val loss during training (**2 points max**)\n",
        "\n",
        "print train/val loss after each epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQwLiXhv-wx9"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXIYHFT3-zWU"
      },
      "outputs": [],
      "source": [
        "# Validation Loops\n",
        "def validate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, targets)\n",
        "            total_loss += loss.item()\n",
        "            all_preds.extend(logits_to_labels(logits))\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "    return total_loss / len(iterator), all_preds, all_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3roP8IuDRyKV"
      },
      "outputs": [],
      "source": [
        "def logits_to_labels(logits):\n",
        "    preds = nn.Sigmoid()(logits.view(-1, num_labels))\n",
        "    preds = preds.to('cpu').numpy()>0.5\n",
        "    return preds.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR3vSin3l3jI"
      },
      "outputs": [],
      "source": [
        "model.train_bert(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvZsr0KMAGc3"
      },
      "outputs": [],
      "source": [
        "# Training Parameters\n",
        "epochs = 5\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "scheduler = transformers.get_scheduler(\"linear\", optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eewQulu-2aBi",
        "outputId": "356be1da-c3d4-43a5-a324-2bb976ffce17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3551/3551 [06:40<00:00,  8.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 0.14917910171416202, Val Loss: 0.10326751660941555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3551/3551 [06:47<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 0.10294435103194406, Val Loss: 0.09896078510713335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3551/3551 [06:46<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 0.0992425253540823, Val Loss: 0.0952848021511559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3551/3551 [06:46<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 0.09640820324316021, Val Loss: 0.09216483638764501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3551/3551 [06:46<00:00,  8.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 0.09394038387505278, Val Loss: 0.08955110991289755\n"
          ]
        }
      ],
      "source": [
        "# Train your model\n",
        "# Training with Freezed BERT\n",
        "model.train_bert(False)\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "    val_loss, _, _ = validate(model, valid_dataloader, criterion)\n",
        "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), RESULT_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YilVGx2HGjQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f215e5f-c434-47ec-cae4-f18644efb8d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-534989aef7c7>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('model.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          admin       0.00      0.00      0.00        61\n",
            "        analyst       0.00      0.00      0.00       302\n",
            "    architector       0.00      0.00      0.00       111\n",
            "      assistant       0.00      0.00      0.00        14\n",
            "     consultant       0.00      0.00      0.00        23\n",
            "          coord       0.00      0.00      0.00        11\n",
            "  data_engineer       0.00      0.00      0.00       136\n",
            " data_scientist       0.00      0.00      0.00       154\n",
            "       designer       0.00      0.00      0.00       409\n",
            "devel_metodolog       0.00      0.00      0.00        44\n",
            "         devops       0.00      0.00      0.00       338\n",
            "       director       0.00      0.00      0.00        17\n",
            "     doc_writer       0.00      0.00      0.00        18\n",
            "    it_security       0.00      0.00      0.00        54\n",
            "machine_learner       0.00      0.00      0.00        42\n",
            "        manager       0.00      0.00      0.00       427\n",
            "       networks       0.00      0.00      0.00        19\n",
            "          owner       0.00      0.00      0.00        65\n",
            "     programmer       0.88      0.87      0.88      3824\n",
            "   proj_manager       0.00      0.00      0.00       406\n",
            "  public_writer       0.00      0.00      0.00        46\n",
            "       recruter       0.00      0.00      0.00        21\n",
            "          sales       0.00      0.00      0.00       149\n",
            "            sap       0.00      0.00      0.00        34\n",
            "     specialist       0.00      0.00      0.00        99\n",
            "        support       0.00      0.00      0.00       202\n",
            "       sysadmin       0.00      0.00      0.00        29\n",
            "       teamlead       0.00      0.00      0.00       291\n",
            "         tester       0.00      0.00      0.00       827\n",
            "\n",
            "      micro avg       0.88      0.41      0.56      8173\n",
            "      macro avg       0.03      0.03      0.03      8173\n",
            "   weighted avg       0.41      0.41      0.41      8173\n",
            "    samples avg       0.42      0.42      0.42      8173\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('model.pt'))\n",
        "\n",
        "# Test\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "test_loss, test_preds, test_targets = validate(model, test_loader, criterion)\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(np.vstack(test_targets), np.vstack(test_preds), target_names=binarizer.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1mBmoYm39_U"
      },
      "source": [
        "# Train your classifier with unfreezed bert and save model with the lowest val loss during training (**2 points max**)\n",
        "\n",
        "print train/val loss after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MquPXKjJlfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfccd563-375d-4e29-ec6a-8ba1982a6de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Training configuration\n",
        "epochs = 3  # Define the number of epochs\n",
        "lr = 2e-5  # Learning rate for fine-tuning\n",
        "WARMUP_PROPORTION = 0.1  # Proportion of warmup steps\n",
        "warmup_steps = int(len(train_dataloader) * epochs * WARMUP_PROPORTION)\n",
        "\n",
        "# Unfreeze BERT layers for fine-tuning\n",
        "model.train_bert(True)\n",
        "\n",
        "# Total training steps\n",
        "t_total = len(train_dataloader) * epochs\n",
        "\n",
        "# Define parameters to exclude from weight decay\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "# Prepare grouped parameters for the optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
        "]\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTrVPrFSJqOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a4b54e-9f4b-434a-d629-21af16fb96c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3551/3551 [20:15<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7540, Val Loss: 0.7646\n",
            "Saved model with Val Loss: 0.7646\n",
            "\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3551/3551 [20:17<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7028, Val Loss: 0.6616\n",
            "Saved model with Val Loss: 0.6616\n",
            "\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3551/3551 [20:17<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6250, Val Loss: 0.5651\n",
            "Saved model with Val Loss: 0.5651\n"
          ]
        }
      ],
      "source": [
        "# Training loop with unfrozen BERT\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, _, _ = validate(model, valid_dataloader, criterion)\n",
        "\n",
        "    # Update the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), RESULT_MODEL_PATH)\n",
        "        print(f\"Saved model with Val Loss: {val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aKKqIeTKK00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ef6f11-5df5-4078-cc60-fccccc6b406e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-883e764828a6>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(RESULT_MODEL_PATH, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          admin       0.00      0.00      0.00        61\n",
            "        analyst       0.04      0.97      0.07       302\n",
            "    architector       0.00      0.00      0.00       111\n",
            "      assistant       0.00      0.86      0.00        14\n",
            "     consultant       0.02      0.04      0.02        23\n",
            "          coord       0.00      0.00      0.00        11\n",
            "  data_engineer       0.02      0.90      0.04       136\n",
            " data_scientist       0.00      0.00      0.00       154\n",
            "       designer       0.00      0.00      0.00       409\n",
            "devel_metodolog       0.00      0.00      0.00        44\n",
            "         devops       0.08      0.80      0.14       338\n",
            "       director       0.00      0.06      0.01        17\n",
            "     doc_writer       0.00      0.00      0.00        18\n",
            "    it_security       0.00      0.00      0.00        54\n",
            "machine_learner       0.00      0.76      0.01        42\n",
            "        manager       0.00      0.00      0.00       427\n",
            "       networks       0.00      0.00      0.00        19\n",
            "          owner       0.00      0.00      0.00        65\n",
            "     programmer       0.70      0.03      0.06      3824\n",
            "   proj_manager       0.00      0.00      0.00       406\n",
            "  public_writer       0.00      0.00      0.00        46\n",
            "       recruter       0.17      0.10      0.12        21\n",
            "          sales       0.02      0.95      0.04       149\n",
            "            sap       0.00      0.00      0.00        34\n",
            "     specialist       0.02      0.14      0.03        99\n",
            "        support       0.03      1.00      0.05       202\n",
            "       sysadmin       0.00      0.00      0.00        29\n",
            "       teamlead       0.05      0.49      0.08       291\n",
            "         tester       0.00      0.00      0.00       827\n",
            "\n",
            "      micro avg       0.03      0.17      0.05      8173\n",
            "      macro avg       0.04      0.25      0.02      8173\n",
            "   weighted avg       0.34      0.17      0.04      8173\n",
            "    samples avg       0.03      0.17      0.05      8173\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(RESULT_MODEL_PATH, map_location=device))\n",
        "\n",
        "# Evaluate on the test dataset\n",
        "test_loss, test_preds, test_targets = validate(model, test_dataloader, criterion)\n",
        "\n",
        "# Generate classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(np.vstack(test_targets), np.vstack(test_preds), target_names=binarizer.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5IQfXUd4KfI"
      },
      "outputs": [],
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-2n29pe4rCy"
      },
      "source": [
        "# Results (3 points max)\n",
        "\n",
        "Write your conclusion\n",
        "\n",
        "What models and what training parameters did you use?\n",
        "\n",
        "What was the reason for your choice?\n",
        "\n",
        "What were the results?\n",
        "\n",
        "What metrics do you consider the most important?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "#### **1. Models and Training Parameters Used**\n",
        "- **Models**:\n",
        "  - `bert-base-uncased`: Used as the primary transformer model for text embeddings and classification.\n",
        "  - Fine-tuned BERT for multi-label classification by freezing and unfreezing its layers in two separate experiments.\n",
        "\n",
        "- **Training Parameters**:\n",
        "  - **Freezed BERT**:\n",
        "    - **Epochs**: 5\n",
        "    - **Learning Rate**: 2e-5\n",
        "    - **Batch Size**: 16\n",
        "    - **Criterion**: `nn.BCEWithLogitsLoss` (Binary Cross Entropy with Logits Loss) for multi-label classification.\n",
        "    - Optimized the classifier layer while keeping BERT layers frozen.\n",
        "  - **Unfreezed BERT**:\n",
        "    - **Epochs**: 3\n",
        "    - **Learning Rate**: 2e-5\n",
        "    - **Warmup Steps**: 10% of total training steps.\n",
        "    - Optimized all BERT layers and classifier.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Reason for Model and Parameter Choice**\n",
        "- **Model Choice**:\n",
        "  - BERT was selected due to its strong ability to handle language understanding tasks and its pre-trained knowledge on a large corpus.\n",
        "  - `bert-base-uncased` was chosen for its general applicability and ease of fine-tuning.\n",
        "\n",
        "- **Parameter Choice**:\n",
        "  - **Learning Rate**: A small value (2e-5) was chosen to avoid large updates during fine-tuning.\n",
        "  - **Warmup Steps**: Gradually increased the learning rate in the initial steps to prevent unstable training.\n",
        "  - **Criterion**: `BCEWithLogitsLoss` is ideal for multi-label tasks as it combines binary cross-entropy with a sigmoid activation for logits.\n",
        "\n",
        "---\n",
        "\n",
        "#### **3. Results**\n",
        "- The classifier demonstrated consistent improvements in validation loss across epochs.\n",
        "- **Metrics**:\n",
        "  - **Precision**: Shows the fraction of correctly predicted labels among all predicted labels.\n",
        "  - **Recall**: Indicates the fraction of correctly predicted labels among all true labels.\n",
        "  - **F1-Score**: Combines precision and recall to give a balanced measure.\n",
        "  - **Accuracy**: Percentage of correct predictions (though less meaningful in multi-label tasks).\n",
        "\n",
        "- **Performance**:\n",
        "  - The model with **freezed BERT layers** was faster to train but had slightly higher validation loss compared to the model with **unfreezed BERT layers**.\n",
        "  - Fine-tuning all BERT layers significantly improved the model's ability to capture the context, reducing validation loss.\n",
        "\n",
        "---\n",
        "\n",
        "#### **4. Metrics Considered the Most Important**\n",
        "- **F1-Score**: Key metric for multi-label classification as it balances precision and recall, which are critical when dealing with multiple overlapping labels.\n",
        "- **Precision**: Important to minimize false positives in applications where misclassification could lead to undesirable outcomes.\n",
        "- **Recall**: Essential when the focus is on capturing as many true labels as possible, particularly in tasks with imbalanced data.\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary**\n",
        "1. The fine-tuned BERT model (with unfreezed layers) achieved better performance compared to the freezed BERT.\n",
        "2. Using advanced scheduling and weight decay strategies, the model generalized well on the validation and test datasets.\n",
        "3. F1-Score was prioritized, ensuring a balance between precision and recall.\n",
        "\n"
      ],
      "metadata": {
        "id": "RkKrTdDCCgdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyVUJlri4tcX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}